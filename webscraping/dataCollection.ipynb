{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fed139-4176-45a9-9e62-3b95ff1ece62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4d30d26-2e68-4efe-95c4-0fc11536d2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Google Digital Marketing & E-commerce\n",
      "Description: Skills you'll gain: Data Storytelling, Search Engine Marketing, Media Planning, Social Media Marketing, Google Ads, Email Marketing, Social Media Strategy, Search Engine Optimization, Order Fulfillment, Social Media Management, Performance Measurement, Spreadsheet Software, A/B Testing, Customer Retention, E-Commerce, Campaign Management, Loyalty Programs, Marketing, Interviewing Skills, Applicant Tracking Systems\n",
      "Link: https://www.coursera.org/professional-certificates/google-digital-marketing-ecommerce\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "\n",
    "# Define the search query\n",
    "s = \"digital marketing\"\n",
    "\n",
    "# Initialize the Chrome driver\n",
    "service = Service(executable_path=r\"C:\\Users\\hp\\Data Science ML\\webscraping\\chromedriver.exe\")\n",
    "driver = webdriver.Chrome(service=service)\n",
    "driver.get('https://www.coursera.org/')\n",
    "time.sleep(3)\n",
    "\n",
    "# Search bar input\n",
    "fill = driver.find_element(By.XPATH, '//div//input[@class=\"react-autosuggest__input\"]')\n",
    "fill.send_keys(s + Keys.ENTER)\n",
    "time.sleep(5)\n",
    "\n",
    "# Data containers\n",
    "platform, head, des, revw, link, image = [], [], [], [], [], []\n",
    "\n",
    "# Get all course cards\n",
    "cards = driver.find_elements(By.XPATH, '//li[@class=\"cds-9 css-0 cds-11 cds-grid-item cds-56 cds-64 cds-76 cds-90\"]')\n",
    "\n",
    "for i in cards:\n",
    "    try:\n",
    "        platform.append(\"coursera\")\n",
    "        \n",
    "        # Use relative XPath\n",
    "        head1 = i.find_element(By.XPATH, './/h3[@class=\"cds-CommonCard-title css-6ecy9b\"]').text.strip()\n",
    "        head.append(head1)\n",
    "\n",
    "        des1 = i.find_element(By.XPATH, './/div[@class=\"cds-ProductCard-body\"]//p[@class=\"css-vac8rf\"]').text.strip()\n",
    "        des.append(des1)\n",
    "\n",
    "        revw1 = i.find_element(By.XPATH, './/div[@class=\"cds-ProductCard-footer\"]//div[@class=\"css-vac8rf\"]').text.strip()\n",
    "        revw.append(revw1)\n",
    "\n",
    "        url = i.find_element(By.XPATH, './/a').get_attribute('href')\n",
    "        link.append(url)\n",
    "\n",
    "        img_elem = i.find_element(By.XPATH, './/img')\n",
    "        img_url = img_elem.get_attribute('src') or img_elem.get_attribute('data-src')\n",
    "        image.append(img_url)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing a card: {e}\")\n",
    "        continue\n",
    "\n",
    "time.sleep(2)\n",
    "driver.quit()\n",
    "\n",
    "# Optional: Print one entry to verify\n",
    "print(f\"Title: {head[0]}\\nDescription: {des[0]}\\nLink: {link[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d81b7e5-274e-46bf-aaad-fc4f1188489a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47f0de2c-9670-47cd-9d55-44a5723a7dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "\n",
    "service=Service(executable_path=r\"C:\\Users\\hp\\Data Science ML\\webscraping\\chromedriver.exe\")\n",
    "driver=webdriver.Chrome(service=service)\n",
    "\n",
    "userit=\"robotics and machine\"\n",
    "newstr=userit.replace(\" \",\"+\")\n",
    "url='https://www.udemy.com/courses/search/?src=ukw&q='+newstr\n",
    "\n",
    "driver.get(url)\n",
    "time.sleep(6)\n",
    "\n",
    "# time.sleep(5)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eaabc2cd-f64b-4a4c-976f-1649fc9307e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "robotics+and+machine\n"
     ]
    }
   ],
   "source": [
    "userit=\"robotics and machine\"\n",
    "newstr=userit.replace(\" \",\"+\")\n",
    "print(newstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e27552c-932d-474d-824b-368d47df5829",
   "metadata": {},
   "outputs": [],
   "source": [
    "skills = [\n",
    "    \"AI and Machine Learning\",\n",
    "    \"Data Science and Analytics\",\n",
    "    \"Full-Stack Web Development\",\n",
    "    \"Cloud Computing\",\n",
    "    \"Cybersecurity\",\n",
    "    \"Mobile App Development\",\n",
    "    \"Python Programming\",\n",
    "    \"Digital Marketing\",\n",
    "    \"Content Creation & Copywriting\",\n",
    "    \"UX/UI Design\",\n",
    "    \"Blogging\",\n",
    "    \"Video Content Creation\",\n",
    "    \"Graphic Design\",\n",
    "    \"Project Management\",\n",
    "    \"Financial & Investment Analysis\",\n",
    "    \"Sales and Negotiation\",\n",
    "    \"Entrepreneurship Development\",\n",
    "    \"Adaptability and Resilience\",\n",
    "    \"Leadership and Team Building\",\n",
    "    \"Problem-Solving and Critical Thinking\",\n",
    "    \"Communication and Networking\",\n",
    "    \"Financial Literacy\"\n",
    "]\n",
    "\n",
    "# print(in_demand_skills_india)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6c28935c-7e1a-43e3-a71e-9638f533c1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.chrome.service import Service\n",
    "# from selenium.webdriver.common.by import By\n",
    "# from selenium.webdriver.common.keys import Keys\n",
    "# from selenium.webdriver.support.ui import WebDriverWait\n",
    "# from selenium.webdriver.support import expected_conditions as EC\n",
    "# import time\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "# def coursera(s):\n",
    "#     service = Service(executable_path=r\"C:\\Users\\hp\\Data Science ML\\webscraping\\chromedriver.exe\")\n",
    "#     driver = webdriver.Chrome(service=service)\n",
    "#     driver.maximize_window()\n",
    "  \n",
    "#     coursera\n",
    "#     driver.get('https://www.coursera.org/')\n",
    "#     time.sleep(3)\n",
    "    \n",
    "#     # Search bar input\n",
    "#     fill = driver.find_element(By.XPATH, '//div//input[@class=\"react-autosuggest__input\"]')\n",
    "#     fill.send_keys(s + Keys.ENTER)\n",
    "#     time.sleep(5)\n",
    "    \n",
    "#     # Data containers\n",
    "#     cor=[]\n",
    "#     platform, head, des, revw, link, image = [], [], [], [], [], []\n",
    "    \n",
    "#     # Get all course cards\n",
    "#     cards = driver.find_elements(By.XPATH, '//li[@class=\"cds-9 css-0 cds-11 cds-grid-item cds-56 cds-64 cds-76 cds-90\"]')\n",
    "    \n",
    "#     for i in cards:\n",
    "#         cor.append(s)\n",
    "#         platform.append(\"coursera\")\n",
    "#         try:\n",
    "            \n",
    "#             # Use relative XPath\n",
    "#             head1 = i.find_element(By.XPATH, './/h3[@class=\"cds-CommonCard-title css-6ecy9b\"]').text.strip()\n",
    "#             head.append(head1)\n",
    "#         except:\n",
    "#             head.append(np.nan)\n",
    "#         try:\n",
    "#             des1 = i.find_element(By.XPATH, './/div[@class=\"cds-ProductCard-body\"]//p[@class=\"css-vac8rf\"]').text.strip()\n",
    "#             des.append(des1)\n",
    "#         except:\n",
    "#             des.append(np.nan)\n",
    "#         try:\n",
    "#             revw1 = i.find_element(By.XPATH, './/div[@class=\"cds-ProductCard-footer\"]//div[@class=\"css-vac8rf\"]').text.strip()\n",
    "#             revw.append(revw1)\n",
    "#         except:\n",
    "#             revw.append(np.nan)\n",
    "#         try:\n",
    "#             url = i.find_element(By.XPATH, './/a').get_attribute('href')\n",
    "#             link.append(url)\n",
    "#         except:\n",
    "#             link.append(np.nan)\n",
    "#         try:\n",
    "#             img_elem = i.find_element(By.XPATH, './/img')\n",
    "#             img_url = img_elem.get_attribute('src') or img_elem.get_attribute('data-src')\n",
    "#             image.append(img_url)\n",
    "#         except:\n",
    "#             image.append(np.nan)\n",
    "    \n",
    "#     time.sleep(2)\n",
    "#     driver.quit()\n",
    "#     return {\"platform\":platform,\"head\":head, \"review\":revw, \"description\":des , \"image\":image, \"url\":link, \"course\":cor }\n",
    "\n",
    "    \n",
    "# def simplearn(s):\n",
    "#     service = Service(executable_path=r\"C:\\Users\\hp\\Data Science ML\\webscraping\\chromedriver.exe\")\n",
    "#     driver = webdriver.Chrome(service=service)\n",
    "#     driver.maximize_window()\n",
    "#     driver.get('https://www.simplilearn.com/')\n",
    "    \n",
    "    \n",
    "#     wait = WebDriverWait(driver, 10)\n",
    "#     fill = wait.until(EC.presence_of_element_located((By.ID, \"header_srch\")))\n",
    "#     fill.send_keys(s + Keys.ENTER)\n",
    "    \n",
    "#     time.sleep(5)\n",
    "#     cards = driver.find_elements(By.XPATH, './/li[@class=\"new-search-list\"]')\n",
    "    \n",
    "#     platform, head, des, revw, link, image = [], [], [], [], [], []\n",
    "#     cor=[]\n",
    "#     # .//div[@class=\"search-cat-logo\n",
    "#     for i in cards:\n",
    "#         cor.append(s)\n",
    "#         platform.append('simplilearn')\n",
    "#         try:\n",
    "#             head1 = i.find_element(By.XPATH, './/div[@class=\"search-cat-info\"]//h4').text.strip()\n",
    "#             head.append(head1)\n",
    "#         except Exception as e:\n",
    "#             print(\"Head Error:\", e)\n",
    "#             head.append(np.nan)\n",
    "    \n",
    "#         try:\n",
    "#             tags = i.find_elements(By.XPATH, './/ul[@class=\"search_skills_covered\"]//li[@class=\"search-chip\"]')\n",
    "#             string1 = \",\".join([tag.text.strip() for tag in tags])\n",
    "#             des.append(string1)\n",
    "#         except:\n",
    "#             des.append(np.nan)\n",
    "    \n",
    "#         try:\n",
    "#             span_text = np.nan\n",
    "#             spans = i.find_elements(By.XPATH, './/ul//span[@class=\"duration-title\"]')\n",
    "#             for span in spans:\n",
    "#                 span_text = span.text.strip()\n",
    "#                 break\n",
    "#             revw.append(span_text)\n",
    "    \n",
    "#             url = i.find_element(By.XPATH, './/a').get_attribute('href')\n",
    "#             link.append(url)\n",
    "#         except Exception as e:\n",
    "#             print(\"Revw/Link Error:\", e)\n",
    "#             revw.append(np.nan)\n",
    "#             link.append(np.nan)\n",
    "    \n",
    "#         try:\n",
    "#             img = i.find_element(By.XPATH, './/div[@class=\"search-collab-logo\"]//img').get_attribute('src')\n",
    "#             image.append(img)\n",
    "#         except Exception as e:\n",
    "#             try:\n",
    "#                 img1=i.find_element(By.XPATH, './/div[@class=\"search-cat-logo\"]//img').get_attribute('src')\n",
    "#                 print(\"Image Error:\", e)\n",
    "#                 image.append(img1)\n",
    "#             except:\n",
    "#                 print(\"Image Error:\", e)\n",
    "#                 image.append(np.nan)\n",
    "    \n",
    "#     driver.quit()\n",
    "#     return {\"platform\":platform,\"head\":head, \"review\":revw, \"description\":des , \"image\":image, \"url\":link, \"course\":cor }\n",
    "\n",
    "# def edx(s):\n",
    "#     # Initialize the Chrome driver\n",
    "#     service = Service(executable_path=r\"C:\\Users\\hp\\Data Science ML\\webscraping\\chromedriver.exe\")\n",
    "#     driver = webdriver.Chrome(service=service)\n",
    "#     driver.maximize_window()\n",
    "#     driver.get('https://www.edx.org/')\n",
    "    \n",
    "#     wait = WebDriverWait(driver, 10)\n",
    "    \n",
    "#     # Wait for the search input and enter the search query\n",
    "#     xpath = '//input[@class=\"border-0 grow focus-visible:ring-0 focus-visible:ring-offset-0 [&::-webkit-search-cancel-button]:hidden rounded w-[230px] h-[44px] shadow-none\"]'\n",
    "#     fill = wait.until(EC.presence_of_element_located((By.XPATH, xpath)))\n",
    "#     fill.send_keys(s + Keys.ENTER)\n",
    "    \n",
    "#     time.sleep(5)\n",
    "    \n",
    "#     # Click on the \"Courses\" tab (if it appears)\n",
    "#     coursediv = driver.find_elements(By.XPATH, './/div[@class=\"flex justify-between items-center mt-4 mb-2\"]')\n",
    "#     for i in coursediv:\n",
    "#         try:\n",
    "#             text = i.find_element(By.XPATH, './/h3').text.strip()\n",
    "#             print(text)\n",
    "#             if text == 'Courses':\n",
    "                \n",
    "#                 i.find_element(By.XPATH, './/button').click()\n",
    "#                 break\n",
    "#         except:\n",
    "#             continue\n",
    "    \n",
    "#     time.sleep(10)\n",
    "    \n",
    "#     # Initialize data containers\n",
    "#     platform, head, des, revw, link, image = [], [], [], [], [], []\n",
    "#     cor=[]\n",
    "    \n",
    "#     # Find all course cards\n",
    "#     cards = driver.find_elements(By.XPATH, '//div[@class=\"grid grid-cols-1 md:grid-cols-2 xl:grid-cols-3 gap-4 py-4\"]//div[@class=\"flex justify-center\"]')\n",
    "    \n",
    "#     for i in cards:\n",
    "#         cor.append(s)\n",
    "#         platform.append(\"edx\")\n",
    "    \n",
    "#         # 🛠️ FIXED: find_element instead of find_elements + missing .text\n",
    "#         try:\n",
    "#             head1 = i.find_element(By.XPATH, './/span[@class=\"font-bold text-lg m-0 break-words line-clamp-3 text-gray-800 overflow-hidden text-ellipsis\"]').text.strip()\n",
    "#             head.append(head1)\n",
    "#         except:\n",
    "#             head.append(np.nan)\n",
    "    \n",
    "#         des.append(np.nan)\n",
    "    \n",
    "#         # 🛠️ FIXED: wrap in try block\n",
    "#         try:\n",
    "#             revw1 = i.find_element(By.XPATH, './/span[@class=\"truncate text-gray-800 text-md\"]').text.strip()\n",
    "#             revw.append(revw1)\n",
    "#         except:\n",
    "#             revw.append(np.nan)\n",
    "    \n",
    "#         try:\n",
    "#             url = i.find_element(By.XPATH, './/a').get_attribute('href')\n",
    "#             link.append(url)\n",
    "#         except:\n",
    "#             link.append(np.nan)\n",
    "    \n",
    "#         # 🛠️ FIXED: typo in append() → \"appaned\"\n",
    "#         try:\n",
    "#             img = i.find_element(By.XPATH, './/img[@class=\"optanon-category-C0001 bg-white shadow absolute p-2 !mt-0 rounded h-[56px] w-[7.25rem] left-4 object-scale-down object-center\"]').get_attribute('src')\n",
    "#             image.append(img)\n",
    "#         except:\n",
    "#             image.append(np.nan)\n",
    "    \n",
    "#     # Close the browser\n",
    "#     driver.quit()\n",
    "#     return {\"platform\":platform,\"head\":head, \"review\":revw, \"description\":des , \"image\":image, \"url\":link,\"course\":cor }\n",
    "\n",
    "# def learnvern(s):\n",
    "#     service=Service(executable_path=r\"C:\\Users\\hp\\Data Science ML\\webscraping\\chromedriver.exe\")\n",
    "#     driver=webdriver.Chrome(service=service)\n",
    "#     driver.maximize_window()\n",
    "#     text=s.replace(\" \",\"%20\")\n",
    "#     url=\"https://www.learnvern.com/courses?txt_search=\"+text\n",
    "#     print(url)\n",
    "#     # https://www.learnvern.com/courses?txt_search=AI%20and%20Machine%20Learning\n",
    "#     driver.get(url)\n",
    "#     time.sleep(10)\n",
    "    \n",
    "#     cards=driver.find_elements(By.XPATH,'//div[@class=\"course-item d-inline-block align-items-stretch\"]')\n",
    "    \n",
    "#     head=[]\n",
    "#     link=[]\n",
    "#     revw=[]\n",
    "#     img=[]\n",
    "#     platform=[]\n",
    "#     des=[]\n",
    "#     cor=[]\n",
    "#     for i in cards:\n",
    "#         cor.append(s)\n",
    "#         des.append(np.nan)\n",
    "#         platform.append(\"learnvern\")\n",
    "#         try:\n",
    "#             heading=i.find_element(By.XPATH,'.//a[@class=\"card-title courses-card-title\"]')\n",
    "#             head.append(heading.text.strip())\n",
    "#         except:\n",
    "#             head.append(np.nan)\n",
    "#         try:\n",
    "#             url=link.append(heading.get_attribute('href'))\n",
    "#         except:\n",
    "#             link.append(np.nan)\n",
    "#         try:\n",
    "#             xpath1='.//div[@class=\"d-flex flex-row cat-course-meta align-items-center mt-auto\"]//span'\n",
    "#             revw1=i.find_element(By.XPATH,xpath1).text.strip()\n",
    "#             revw.append(revw1)\n",
    "#         except:\n",
    "#             revw.append(np.nan)\n",
    "#         try:\n",
    "#             img1=i.find_element(By.XPATH,'.//img[@class=\"card-img-top d-flex mx-auto\"]')\n",
    "#             url1=img1.get_attribute('src')\n",
    "#             img.append(url1)\n",
    "#         except:\n",
    "#             img.append(np.nan)\n",
    "    \n",
    "#     driver.quit()\n",
    "#     return {\"platform\":platform,\"head\":head, \"review\":revw, \"description\":des , \"image\":img, \"url\":link, \"course\":cor }\n",
    "\n",
    "\n",
    "# import pandas as pd\n",
    "# arr=[]\n",
    "# for i in skills:\n",
    "#     data1=learnvern(i)\n",
    "#     arr.append(data1)\n",
    "#     data2=edx(i)\n",
    "#     arr.append(data2)\n",
    "#     data3=simplearn(i)\n",
    "#     arr.append(data3)\n",
    "#     data4=coursera(i)\n",
    "#     arr.append(data4)\n",
    "# # data=learnvern('AI and Machine Learning')\n",
    "# # pd.DataFrame(data)\n",
    "# # pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0afbc0e1-42a1-4497-8d66-7008a2f449ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# newarr=[]\n",
    "# for i in arr:\n",
    "#     newarr.append(pd.DataFrame(i))\n",
    "# result = pd.concat(newarr, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dec578-8ce5-45c6-bd73-781174b0cd81",
   "metadata": {},
   "source": [
    "# youtube playlist scrapper "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "64b4579f-710e-4beb-8f5b-77299cf24556",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.isna().sum()\n",
    "result.to_csv('datacollected.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb91b11-3a73-4272-b193-3ac39d22ec11",
   "metadata": {},
   "outputs": [],
   "source": [
    " selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the Chrome driver\n",
    "service = Service(executable_path=r\"C:\\Users\\hp\\Data Science ML\\webscraping\\chromedriver.exe\")\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "\n",
    "# //******** yha string modify krlio\n",
    "\n",
    "driver.get('https://www.youtube.com/results?search_query=probability+stat&sp=EgIQAw%253D%253D')\n",
    "\n",
    "wait = WebDriverWait(driver, 10)\n",
    "\n",
    "# Wait for the search input and enter the search query\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Initialize data containers\n",
    "platform, head, prereq, revw, link, image = [], [], [], [], [], []\n",
    "\n",
    "# Find all course cards\n",
    "cards = driver.find_elements(By.XPATH, './/div[@class=\"yt-lockup-view-model-wiz yt-lockup-view-model-wiz--horizontal yt-lockup-view-model-wiz--collection-stack-2\"]')\n",
    "\n",
    "count=0\n",
    "for i in cards:\n",
    "    platform.append(\"youtube\")\n",
    "    prereq.append(\"key\")\n",
    "    \n",
    "    head1=i.find_element(By.XPATH, './/span[@class=\"yt-core-attributed-string yt-core-attributed-string--white-space-pre-wrap\"]')\n",
    "    head.append(head1.text.strip())\n",
    "    \n",
    "    img=i.find_element(By.XPATH,'.//img[@class=\"yt-core-image yt-core-image--fill-parent-height yt-core-image--fill-parent-width yt-core-image--content-mode-scale-aspect-fill yt-core-image--loaded\"]')\n",
    "    image.append(img.get_attribute('src'))\n",
    "\n",
    "    url=i.find_element(By.XPATH,'.//a[@class=\"yt-lockup-view-model-wiz__content-image\"]').get_attribute('href')\n",
    "    link.append(url)\n",
    "    if(count>=4):\n",
    "        break\n",
    "    count+=1\n",
    "# Close the browser\n",
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
